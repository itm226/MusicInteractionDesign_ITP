\documentclass[12pt]{article}
\usepackage[margin = 1in]{geometry}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{titling}

\title{User Path 2: Interactivity}
\author{Ian MacDougald}
\date{February 20th, 2019}

\begin{document}
	\setlength{\droptitle}{-10em}
	\maketitle
	\onehalfspacing
	\section*{User Path}
	
	My project aims towards the design and implementation of a new type of musical instrument in VR, which, in one sense, is not an instrument at all but is in an interactive environment that does not require user-interaction to output meaningful results. As a result, unlike a violin or piano or trumpet, which require precise control to produce musical results, this instrument would replace this paradigm of control or `playing' with one defined by intervention, which is to say that the user can affect, change, or manipulate the agents and parameters of the composition space in ways that are significant, but the significance of such interventions can only be observed and are not themselves interactive. Put another way: I hope to accomplish the design and implementation of an audio-visual instrument/environment where interaction with semi-autonomous digital organisms, which spawn, swarm, react, disperse, reproduce, and evolve, generates the sonic content of musical composition. 
	
	How exactly does the user interact with the populations of the composition space? As stated in previous iterations of this prompt, this project will rely on three different tools\textemdash an Oculus Rift, a Leap Motion Sensor, and SuperCollider. As a result, interaction with the world space will, primarily be tactile with the user handling organisms causing them to die or swarm, contaminating them and, as a result, instigating their evolution or the spread of some virus, or dispersing them across the composition space. In general terms, the user's role should be one of the dangerously curious observer who still holds the ability to profoundly impact or disrupt this otherwise independent world. 
	
	For an immersive instrument of this nature, I believe a description of the user interfaces should describe two different domains\textemdash the real-to-digital interface and the digital-to-digital interface. The real-to-digital interface, which is represented by the hardware of the Oculus Rift, the Leap Motion Sensor, and the Leap Motion SDK supported by the Unity 3D game engine, should allow the player to transport both their mind and their tactile senses into the virtual world. Moreover, for immersion to remain consistent, the digital-to-digital interface\textemdash how the player interacts with the digital elements of the virtual world\textemdash need to be intuitive and as expansive as possible. In this regard, I do not know what approach is best suited. I think this element of the project will need to develop alongside the implementation of the system itself. 
\end{document}